{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### install necessary packages and libraries"
      ],
      "metadata": {
        "id": "YjMOr-WNkVfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "id": "yGZU10yMkVH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import necessary packages and libraries"
      ],
      "metadata": {
        "id": "w6jxjaWMj9m6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWNqkY4Lj6Yp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Flatten, Dropout,Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import gensim.models as gsm\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the dataset"
      ],
      "metadata": {
        "id": "HbPcjWFsmIN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "dataset_file = '/content/drive/MyDrive/new_updated_dataset.csv'\n",
        "\n",
        "data=pd.read_csv(dataset_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUDQSk3Sl3_l",
        "outputId": "56c0e1cf-c221-4599-de40-72f567cf539c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import pre-trained models(fasttext and emoji2Vec)"
      ],
      "metadata": {
        "id": "7NkOi8colfzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import fastText model for text\n",
        "\n",
        "fastText_model_path = '/content/drive/MyDrive/cc.si.300.bin/cc.si.300.bin'\n",
        "fasttext.FastText.eprint = lambda x: None\n",
        "ft = fasttext.load_model(fastText_model_path)\n",
        "\n",
        "\n",
        "#import emoji2Vec model for emojis\n",
        "\n",
        "e2v = gsm.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/emoji2vec.bin', binary=True)"
      ],
      "metadata": {
        "id": "jYyHFU0YkNC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "shuffle the dataset"
      ],
      "metadata": {
        "id": "rINgHTJcm9i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = shuffle(data)\n"
      ],
      "metadata": {
        "id": "ciWCT9Qlm-H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the dataset"
      ],
      "metadata": {
        "id": "x5kkIL4WoLkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# combined the emoji and text column for split in same points\n",
        "\n",
        "combined_data = pd.concat([data['comment'], data['expression_emoji']], axis=1)\n",
        "\n",
        "#split the dataset into train, test, validation\n",
        "combined_train, combined_test, y_train, y_test = train_test_split(combined_data, data['label'], test_size=0.2, random_state=42, stratify=data['label'])\n",
        "\n",
        "combined_actual_train,combined_val,y_actual_train,y_val=train_test_split(combined_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "\n",
        "#devide each column under train, test, validation\n",
        "X_actual_train_text, X_actual_train_emoji = combined_actual_train['comment'], combined_actual_train['expression_emoji']\n",
        "\n",
        "X_test_text, X_test_emoji= combined_test['comment'], combined_test['expression_emoji']\n",
        "\n",
        "x_val_text,x_val_emoji=combined_val['comment'],combined_val['expression_emoji']\n"
      ],
      "metadata": {
        "id": "bFvIKiC7FWT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform word to vector using fastText model for comment column"
      ],
      "metadata": {
        "id": "6_hLp25GnR8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_vector(word):\n",
        "    try:\n",
        "        wordVec=ft.get_word_vector(word)\n",
        "\n",
        "\n",
        "        return wordVec\n",
        "    except KeyError:\n",
        "        return np.zeros(ft.get_dimension())\n",
        "\n",
        "\n",
        "\n",
        "def get_sentence_vector(sentence):\n",
        "\n",
        "    if not isinstance(sentence, str):\n",
        "        sentence = str(sentence)\n",
        "    vectors = [get_word_vector(word) for word in sentence.split()]\n",
        "\n",
        "    return np.mean(vectors, axis=0)"
      ],
      "metadata": {
        "id": "Pwl7cVLmnTUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_text_vectors=np.array([get_sentence_vector(sentence) for sentence in X_actual_train_text])\n",
        "X_test_text_vectors=np.array([get_sentence_vector(sentence) for sentence in X_test_text])\n",
        "x_text_val_vectors=np.array([get_sentence_vector(sentence) for sentence in x_val_text])"
      ],
      "metadata": {
        "id": "jSKIuYT5pbx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " perform Emoji to vector task using emoji2Vec model for expression_emoji column"
      ],
      "metadata": {
        "id": "Ctj3GEOFrTN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(get_word_vector('‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑Ä‡∑è')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eIGQsmyrYmw",
        "outputId": "932f41b4-4c7d-4169-8e18-eb23973d319f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0009083676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(get_sentence_vector('‡∂∏‡∑ö‡∂ö‡∑ô‡∂≠‡∑ä ‡∑Ä‡∑ô‡∂±‡∂∏‡∂∏ ‡∂Ü‡∂≠‡∂Ω‡∑ä ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑Ä‡∑è!!')))"
      ],
      "metadata": {
        "id": "bv_2bCnCzMKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_emoji_vector(emoji):\n",
        "\n",
        "    try:\n",
        "        value=-e2v[emoji]\n",
        "\n",
        "        return value\n",
        "\n",
        "    except KeyError:\n",
        "        return np.zeros(300)"
      ],
      "metadata": {
        "id": "I-Ut5-b_rUTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textHate=np.mean(get_word_vector('‡∂¥‡∑ú‡∂±‡∑ä‡∂±‡∂∫‡∑ô‡∂ö‡∑ä‡∂Ø'))\n",
        "print(textHate)\n",
        "emojiHate=np.mean(get_emoji_vector('üò°'))\n",
        "print(emojiHate)"
      ],
      "metadata": {
        "id": "w_beAu6A4H-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textNon=np.mean(get_word_vector('‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑Ä‡∑è'))\n",
        "print(textNon)\n",
        "emojiNon=np.mean(get_emoji_vector('üòÇ'))\n",
        "print(emojiNon)\n"
      ],
      "metadata": {
        "id": "MxLae8NB6rmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textNon=np.mean(get_word_vector('‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑Ä‡∑è'))\n",
        "print(textNon)\n",
        "emojiNon=np.mean(get_emoji_vector('ü•∞'))\n",
        "print(emojiNon)\n"
      ],
      "metadata": {
        "id": "jxqVt35eI3lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CombineHate=np.mean([textHate,emojiHate])\n",
        "print(CombineHate)\n",
        "\n",
        "combineNon=np.mean([textNon,emojiNon])\n",
        "print(combineNon)\n",
        "\n",
        "combineMid=np.mean([textHate,emojiNon])\n",
        "print(combineMid)"
      ],
      "metadata": {
        "id": "Qo2oA17w7rkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_emoji_vectors = np.array([get_emoji_vector(emoji) for emoji in X_actual_train_emoji])\n",
        "X_test_emoji_vectors = np.array([get_emoji_vector(emoji) for emoji in X_test_emoji])\n",
        "X_val_emoji_vectors=np.array([get_emoji_vector(emoji) for emoji in x_val_emoji])"
      ],
      "metadata": {
        "id": "LE9XS6JEra5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bGK30DrFlrwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined the emoji and comment vectors"
      ],
      "metadata": {
        "id": "y7knzRnJrjx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_vectors=np.mean([X_train_text_vectors,X_train_emoji_vectors],axis=0)\n",
        "\n",
        "X_test_vectors=np.mean([X_test_emoji_vectors,X_test_text_vectors],axis=0)\n",
        "\n",
        "X_val_vectors=np.mean([x_text_val_vectors,X_val_emoji_vectors],axis=0)"
      ],
      "metadata": {
        "id": "0OexuR3Frjc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define model nature and aspects"
      ],
      "metadata": {
        "id": "h0amIYIbr4tI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True)\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train),y= y_train)\n",
        "\n",
        "class_weight_dict = dict(enumerate(class_weights))"
      ],
      "metadata": {
        "id": "IeuMnzCEr4Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert target classes into onehot encoding\n",
        "num_classes = 3\n",
        "y_actual_train_encoded = to_categorical(y_actual_train, num_classes=num_classes)\n",
        "y_val_encoded = to_categorical(y_val, num_classes=num_classes)\n",
        "y_test_encoded=to_categorical(y_test,num_classes=num_classes)"
      ],
      "metadata": {
        "id": "W85e1ObnAqOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the model"
      ],
      "metadata": {
        "id": "JtaDlekp-Kw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Feed forword neural network"
      ],
      "metadata": {
        "id": "nRW7LzoVHYhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 300\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(512,activation='relu',input_dim=input_dim))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "4PnUipbrHKyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "oEQVUSUVJFvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train_vectors, y_actual_train_encoded, epochs=100, batch_size=64, validation_data=(X_val_vectors, y_val_encoded), callbacks=[early_stopping], class_weight=class_weight_dict)\n"
      ],
      "metadata": {
        "id": "Z3U6pdOuiVNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "\n",
        "prediction=model.predict(X_test_vectors)\n",
        "loss, accuracy = model.evaluate(X_test_vectors, y_test_encoded)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "mhZON-9eO1Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "classification report for feedforward neural network"
      ],
      "metadata": {
        "id": "Tx1WTxObcZDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "predicted_classes = np.array(prediction)\n",
        "prediction=prediction.argmax(axis=1)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, prediction))"
      ],
      "metadata": {
        "id": "Z6LNPt1McX7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using LSTM model"
      ],
      "metadata": {
        "id": "XIPzixvpH0FK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_dim = 300\n",
        "\n",
        "modelLSTM = Sequential()\n",
        "timesteps=1\n",
        "\n",
        "modelLSTM.add(Bidirectional(LSTM(128, return_sequences=True,input_shape=(timesteps, input_dim))))\n",
        "modelLSTM.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "\n",
        "modelLSTM.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "vat_yF2Iu4m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the vectors\n",
        "X_train_vecotrs_reshaped = X_train_vectors.reshape(X_train_vectors.shape[0],timesteps, X_train_vectors.shape[1])\n",
        "X_val_vectors_reshaped = X_val_vectors.reshape(X_val_vectors.shape[0], timesteps, X_val_vectors.shape[1])\n",
        "X_test_vecotrs_reshaped = X_test_vectors.reshape(X_test_vectors.shape[0], timesteps, X_test_vectors.shape[1])"
      ],
      "metadata": {
        "id": "AlEsqo1BDKkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "modelLSTM.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'],run_eagerly=True)"
      ],
      "metadata": {
        "id": "qOXBK4TmOQjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(y_actual_train_encoded.shape)\n",
        "# print(X_train_vecotrs_reshaped.shape)\n",
        "# # Remove the extra dimension from the target data\n",
        "y_actual_train_encoded_reshaped  = y_actual_train_encoded.reshape(y_actual_train_encoded.shape[0],1, num_classes)\n",
        "y_val_encoded_reshaped=y_val_encoded.reshape(y_val_encoded.shape[0],1,num_classes)\n",
        "y_actual_train_encoded_reshaped = y_actual_train_encoded_reshaped.reshape(y_actual_train_encoded_reshaped.shape)\n",
        "y_val_encoded_reshaped = y_val_encoded_reshaped.reshape(y_val_encoded_reshaped.shape)\n",
        "y_test_encoded_reshaped=y_test_encoded_reshaped.reshape(y_test_encoded_reshaped.shape)\n",
        "# y_test_encoded_reshaped=y_test_encoded.reshape(y_test_encoded.shape[0],1,num_classes)\n",
        "# y_actual_train_encoded_reshaped = y_actual_train_encoded_reshaped.reshape(-1, 1, 3)\n",
        "# print(y_actual_train_encoded_reshaped.shape)\n",
        "# # y_actual_train_encoded_reshaped = y_actual_train_encoded_reshaped.reshape(-1, 1, 3)\n",
        "print(y_actual_train_encoded_reshaped.shape)\n",
        "print(y_val_encoded_reshaped.shape)\n",
        "print(X_train_vecotrs_reshaped.shape)\n",
        "print(X_val_vectors_reshaped.shape)\n",
        "# print(modelLSTM.output_shape)"
      ],
      "metadata": {
        "id": "CVnsjTd588Cp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd9f70e-c87c-40b4-ddfe-164de4ef356a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5851, 1, 3)\n",
            "(1463, 1, 3)\n",
            "(5851, 1, 300)\n",
            "(1463, 1, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual_train=np.array(y_actual_train)\n",
        "print(X_train_vectors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPjhvHhL-aRJ",
        "outputId": "e83be10e-2838-42fc-9db4-c6f1e5c09e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5851, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM.summary()"
      ],
      "metadata": {
        "id": "61n_eFtw_fld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# y_actual_train_encoded_reshaped = y_actual_train_encoded_reshaped.squeeze()\n",
        "# y_val_encoded_reshaped = y_val_encoded_reshaped.squeeze()\n",
        "# modelLSTM.fit(X_train_vecotrs_reshaped.reshape(-1, 1, 300), y_actual_train_encoded_reshaped.reshape(-1, 1, 3), epochs=100, batch_size=64, validation_data=(X_val_vectors_reshaped.reshape(-1, 1, 300), y_val_encoded_reshaped.reshape(-1, 1, 3)), callbacks=[early_stopping])\n",
        "# modelLSTM.fit(X_train_vecotrs_reshaped, y_actual_train_encoded_reshaped.reshape(-1, 1, 3), epochs=100, batch_size=64, validation_data=(y_val_encoded_reshaped, y_val_encoded), callbacks=[early_stopping])\n",
        "# Train the model\n",
        "modelLSTM.fit(X_train_vecotrs_reshaped, y_actual_train_encoded_reshaped, epochs=100, batch_size=64, validation_data=(X_val_vectors_reshaped, y_val_encoded_reshaped), callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "8qLOPJSbOc3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [],
      "cell_type": "code",
      "metadata": {
        "id": "T1Q1ySOHHVGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test LSTM model\n",
        "\n",
        "prediction=modelLSTM.predict(X_test_vecotrs_reshaped)\n",
        "\n",
        "loss, accuracy = modelLSTM.evaluate(X_test_vecotrs_reshaped, y_test_encoded_reshaped)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "XK8fpx25VsNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification report for LSTM"
      ],
      "metadata": {
        "id": "opQTNU0jV1AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "predicted_classes = np.array(prediction)\n",
        "prediction=prediction.argmax(axis=1)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, prediction))"
      ],
      "metadata": {
        "id": "McVLaQeaV0vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_vecotrs_reshaped = X_train_vectors.reshape(X_train_vectors.shape[0],X_train_vectors.shape[1])\n",
        "X_val_vectors_reshaped = X_val_vectors.reshape(X_val_vectors.shape[0], 1,X_val_vectors.shape[1])\n",
        "X_test_vecotrs_reshaped = X_test_vectors.reshape(X_test_vectors.shape[0],1, X_test_vectors.shape[1])"
      ],
      "metadata": {
        "id": "drA8hDo-V8FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try with KMeans (Optional)"
      ],
      "metadata": {
        "id": "zD-fA3zOkrmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "\n",
        "kmeans.fit(X_train_vectors)\n",
        "\n",
        "predictWithKmeans = kmeans.predict(X_test_vectors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjQQDG51kjmC",
        "outputId": "0eb9f08b-205e-4589-8ef6-5ed6f2d3513d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictWithKmeans)\n",
        "print(\"Accuracy of K-means on test data:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96icpoOOlKA6",
        "outputId": "98ff9972-a1a1-443b-d284-8bb517afb92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of K-means on test data: 0.13504647348277748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "predicted_classes = np.array(predictWithKmeans)\n",
        "\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, predicted_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z_LJFa6mMLy",
        "outputId": "3f626765-61e7-4582-abc8-ec7d26764cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       610\n",
            "           1       0.23      0.40      0.30       610\n",
            "           2       0.00      0.00      0.00       609\n",
            "\n",
            "    accuracy                           0.14      1829\n",
            "   macro avg       0.08      0.13      0.10      1829\n",
            "weighted avg       0.08      0.14      0.10      1829\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try with K nearest Neighbours(Optional)"
      ],
      "metadata": {
        "id": "5aAbDTgCmTdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
        "knn.fit(X_train_vectors, y_actual_train)\n",
        "\n",
        "predictWithKNN = knn.predict(X_test_vectors)"
      ],
      "metadata": {
        "id": "sE6YaXHWmhGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictWithKNN)\n",
        "print(\"Accuracy of KNN on test data:\", accuracy)\n",
        "print(y_test)\n",
        "print(predictWithKNN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y1uwk5bmwtD",
        "outputId": "a8ca278f-39ec-4163-9cdd-abdf316b3b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of KNN on test data: 0.8305084745762712\n",
            "[1 1 2 ... 2 1 1]\n",
            "[0 1 2 ... 2 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "predicted_classes = np.array(predictWithKNN)\n",
        "print(predicted_classes)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, predicted_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDirb4-7m5NG",
        "outputId": "aec49daa-12cd-44d8-c6a3-1d557d430559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 ... 2 1 1]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.76      0.77       610\n",
            "           1       0.75      0.89      0.82       610\n",
            "           2       0.98      0.84      0.91       609\n",
            "\n",
            "    accuracy                           0.83      1829\n",
            "   macro avg       0.84      0.83      0.83      1829\n",
            "weighted avg       0.84      0.83      0.83      1829\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test by manually"
      ],
      "metadata": {
        "id": "SlkXkWC_2zJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re\n",
        "\n",
        "user_comment = input(\"Enter a comment: \")\n",
        "\n",
        "\n",
        "emoji_pattern = re.compile(r'\\p{So}')\n",
        "\n",
        "emojis = emoji_pattern.findall(user_comment)\n",
        "\n",
        "text_without_emojis = emoji_pattern.sub('', user_comment)\n",
        "\n",
        "user_text_vector = get_sentence_vector(user_comment)\n",
        "user_emoji_vector=get_emoji_vector(emojis[0])\n",
        "\n",
        "user_comment_vector=np.mean([user_text_vector,user_emoji_vector],axis=0)\n",
        "\n",
        "user_comment_vector = user_comment_vector.reshape(1,-1)\n",
        "\n",
        "prediction = knn.predict(user_comment_vector)\n",
        "\n",
        "print(f\"Predicted Class: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qUNR9iQ2y9q",
        "outputId": "c3ac566b-b595-4253-d618-884d92c94db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a comment: ‡∑É‡∂Ç‡∑Ñ‡∑í‡∂Ø‡∑í‡∂∫‡∑è‡∑Ä‡∂ß ‡∂Ö‡∑Ä‡∑î‡∂Ω‡∂ö‡∑ä ‡∑Ä‡∑ô‡∂∫‡∑í ‡∂ØüòÇ\n",
            "Predicted Class: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "vFtFl-54Kqzh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}